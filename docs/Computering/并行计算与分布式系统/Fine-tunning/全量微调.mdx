import WordCount from '../../../../src/components/WordCount/WordCount.jsx';

<WordCount>

## 全量微调

在老模型的基础上，使用新的、特定任务的数据集对模型进行全参数的进一步训练，从而全面调整模型的所有权重和参数。

可以理解为矩阵的加法，老模型一个矩阵，新模型一个矩阵，那么老模型的矩阵加一个矩阵等于新模型的矩阵，全量微调调的就是这个矩阵。假如说一个模型需要100亿参数，那么有100亿的老参数就需要100亿的新参数。

可以看出全量微调的思路比较传统和直接，同时也非常复杂。它使用的优化算法是梯度下降法（过拟合预警）。如果数据量够，算力资源丰富，可以考虑用全量微调。

应用全量微调还是比较麻烦，怎么办呢？好在我们不止有全量微调这一种手段。

## LoRA(Low-Rank Adaptation)微调

PAPER: https://arxiv.org/abs/2106.09685

Video: https://www.youtube.com/watch?v=DhRoTONcyZE

通过在预训练模型中引入一个额外的低秩矩阵，并使用特定任务的数据来微调这个矩阵，达到LoRa微调的效果。

在预训练模型的基础上，增加一个可训练的线性层（两个矩阵组成），在微调过程中只更新该线性层的参数。

这个过程有点类似于“狸猫换太子”。

LoRA将模型的权重矩阵分解为两个低秩矩阵的乘积：

将高维的权重矩阵$W$表示为两个低秩矩阵$A$和$B$的乘积：

即：

$W ≈ A·B$

有很高的秩，意味着它可以表示非常复杂的线性变换。高维的权重矩阵$W$就具有很高的秩。

原始的权重矩阵$W$是一个$1000×1000$的高维矩阵，意味着$1000*1000=1000000$个参数。

在LoRA中，我们用两个低秩矩阵A和B来近似权重矩阵$W$，使得$W ≈ A·B$。假设$A$是一个$1000×10$的矩阵，有$1000*10$个参数。假设$B$是一个$10×1000$的矩阵，有$10*1000$个参数。

因此，$A$和$B$的总参数数量为$1000*10+10*1000=20000$个参数。这意味着，LoRA可以将$1000000$个参数的权重矩阵$W$压缩到$20000$个参数的$A$和$B$矩阵中。

只更新低秩矩阵A和B的参数，由于$A$和$B$的参数数量远小于$W$，这就显著减少了需要学习的参数数量，从而降低了计算成本。

LoRA过于简洁的实现方式，导致它对复杂任务表现得并不太好，LoRA对于A和B的结构非常敏感。

</WordCount>